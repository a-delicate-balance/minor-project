{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation of Brain MRI images using U-Net and Trans-U-Net algorithms for Alzheimer's detection\n",
        "---\n",
        "\n",
        "## Summary\n",
        "This is a project exploring Machine learning methods of segmentation of MRI images for extracting MRI images of brain from other tissue present in and around the human skull.\n",
        "\n",
        "---\n",
        "## Implementation of U-Net and Trans-U-Net algorithms\n",
        "\n",
        "### Requirements\n",
        "```\n",
        "!pip install numpy pandas pillow tqdm torch torchvision scikit-learn albumentations matplotlibopencv-python\n",
        "```\n",
        "---\n",
        "### Team\n",
        "|Member                |Github    |\n",
        "|-                     |-         |\n",
        "|Piyush Goyal          |[@PIYUSH-GOYAL1](https://github.com/PIYUSH-GOYAL1)|\n",
        "|Sanidhya Shyam Sagar  |[@Sanidhya-sagar](https://github.com/Sanidhya-sagar)|\n",
        "|Parth                 |[@a-delicate-balance](https://github.com/a-delicate-balance)|\n",
        "|Paras                 |[@paras28-05](https://github.com/paras28-05)|\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2KfQOHX8wlhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "### Imports\n",
        "```markdown\n",
        "1.  os\n",
        "2.  shutil\n",
        "3.  google.colab.drive\n",
        "4.  numpy\n",
        "5.  pandas\n",
        "6.  matplotlib.pyplot\n",
        "7.  glob\n",
        "8.  random\n",
        "9.  cv2\n",
        "10. PIL (pillow)\n",
        "11. albumentations\n",
        "12. torch\n",
        "13. tqdm\n",
        "14. sklearn\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "u5Y0AfntyiXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ieZCr6deZa",
        "outputId": "73dc6e1f-e7b0-4cf9-c556-e528407648c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob  # Filename pattern matching\n",
        "import random\n",
        "import cv2  # Computer vision\n",
        "from PIL import Image  # Image processing\n",
        "\n",
        "import torch\n",
        "import torchvision  # Computer vision tools\n",
        "import torch.nn as nn  # Neural network layers\n",
        "import torch.nn.functional as F  # Neural network functions\n",
        "import torch.utils.data as data  # Data handling utilities\n",
        "import torchvision.transforms as tt  # Image transformations\n",
        "import albumentations as A  # Image augmentations\n",
        "from tqdm import tqdm  # Progress bar\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid  # Image grid layout\n",
        "from torch.utils.data import DataLoader  # Data loading\n",
        "from torchvision.utils import make_grid  # Create image grids\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data for Google Collab Work\n",
        "\n",
        "Requires Data from Google Drive to be imported to the local storage of the runtime, since Google Drive access is slow and time-limited without re-authorization."
      ],
      "metadata": {
        "id": "BY6wIcL3z-bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run from a new runtime once only.\n",
        "\n",
        "if not os.path.exists(\"/content/lgg-mri-segmentation\"):\n",
        "  drive.mount('/content/drive')\n",
        "  shutil.copytree(\"/content/drive/MyDrive/Colab Notebooks/lgg-mri-segmentation\", \"/content/lgg-mri-segmentation\")"
      ],
      "metadata": {
        "id": "nIGuKRWIpoGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b1a1c6-a096-496e-d6a2-4ed211c342c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize set seed randomness\n",
        "\n",
        "Set random seeds to a set seed for reproducibility."
      ],
      "metadata": {
        "id": "2kNWm_Oz0gco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUTNLZMcdeZe"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=0):  # Function to set random seed for reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)  #\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "seed = 0\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Pandas DataFrame\n",
        "\n",
        "Load Image Data in Pandas DataFrame as well as diagnostic data"
      ],
      "metadata": {
        "id": "yIDLvUvI00r9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj2WRHi6deZg"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = \"/content/lgg-mri-segmentation/kaggle_3m/\"\n",
        "\n",
        "# Using glob.glob to collect paths of all mask files in subdirectories\n",
        "mask_files = glob.glob(ROOT_PATH + '*/*_mask*')\n",
        "image_files = [file.replace('_mask', '') for file in mask_files]\n",
        "\n",
        "# Defining a function diagnosis(mask_path) that returns 1\n",
        "# if the maximum pixel value in the mask image (read using cv2) is greater than 0\n",
        "def diagnosis(mask_path):\n",
        "    return 1 if np.max(cv2.imread(mask_path)) > 0 else 0\n",
        "\n",
        "files_df = pd.DataFrame({\"image_path\": image_files,\n",
        "                  \"mask_path\": mask_files,\n",
        "                  \"diagnosis\": [diagnosis(x) for x in mask_files]})\n",
        "\n",
        "files_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HMRiZkTdeZj"
      },
      "outputs": [],
      "source": [
        "print(\"Total of No Alzheimer:\", files_df['diagnosis'].value_counts()[0])\n",
        "print(\"Total of Alzheimer:\", files_df['diagnosis'].value_counts()[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Testing Training Split\n",
        "\n",
        "Splitting the dataseinto testing and training subsets."
      ],
      "metadata": {
        "id": "3jsOFiOW44mB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKCMAEb6deZk"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training data (train_df), validation data (val_df),\n",
        "#and test data (test_df) with specified proportions.\n",
        "train_df, val_df = train_test_split(files_df, stratify=files_df['diagnosis'], test_size=0.1, random_state=0)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "train_df, test_df = train_test_split(train_df, stratify=train_df['diagnosis'], test_size=0.15, random_state=0)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "print(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Plot\n",
        "\n",
        "Plotting sample data of the dataset."
      ],
      "metadata": {
        "id": "P68G1rVf5TK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU3i4lLCdeZm"
      },
      "outputs": [],
      "source": [
        "set_seed()\n",
        "images, masks = [], []\n",
        "df_positive = train_df[train_df['diagnosis']==1].sample(5).values\n",
        "\n",
        "for sample in df_positive:\n",
        "    img = cv2.imread(sample[0])\n",
        "    mask = cv2.imread(sample[1])\n",
        "    images.append(img)\n",
        "    masks.append(mask)\n",
        "images = np.hstack(np.array(images))\n",
        "masks = np.hstack(np.array(masks))\n",
        "\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.4)\n",
        "\n",
        "grid[0].imshow(images)\n",
        "grid[0].set_title('Images', fontsize=15)\n",
        "grid[0].axis('off')\n",
        "grid[1].imshow(masks)\n",
        "grid[1].set_title('Masks', fontsize=15)\n",
        "grid[1].axis('off')\n",
        "grid[2].imshow(images)\n",
        "grid[2].imshow(masks, alpha=0.4)\n",
        "grid[2].set_title('Brain MRI with mask', fontsize=15)\n",
        "grid[2].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Class\n",
        "\n",
        "Class for Dataset with some data handling."
      ],
      "metadata": {
        "id": "px2UzZj05dh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOlBG-TqdeZn"
      },
      "outputs": [],
      "source": [
        "class BrainDataset(data.Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.df.iloc[idx, 0])\n",
        "        image = np.array(image)/255.\n",
        "        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n",
        "        mask = np.array(mask)/255.\n",
        "\n",
        "        if self.transform is not None:\n",
        "            aug = self.transform(image=image, mask=mask)\n",
        "            image = aug['image']\n",
        "            mask = aug['mask']\n",
        "\n",
        "        image = image.transpose((2,0,1))\n",
        "        image = torch.from_numpy(image).type(torch.float32)\n",
        "        image = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n",
        "        mask = np.expand_dims(mask, axis=-1).transpose((2,0,1))\n",
        "        mask = torch.from_numpy(mask).type(torch.float32)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Transformation\n",
        "\n",
        "Define transformations for training, validation, and testing datasets using Albumentations library."
      ],
      "metadata": {
        "id": "e0BoPGwP51eT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7TZw3wAdeZp"
      },
      "outputs": [],
      "source": [
        "# Define transformations for training, validation, and testing datasets using Albumentations library.\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(width=128, height=128, p=1.0),  # Resize images to 128x128 pixels\n",
        "    A.HorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability\n",
        "    A.VerticalFlip(p=0.5),  # Apply vertical flip with 50% probability\n",
        "    A.RandomRotate90(p=0.5),  # Rotate randomly by 90 degrees with 50% probability\n",
        "    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),  # Randomly shift, scale, and rotate\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(width=128, height=128, p=1.0),  # Resize images to 128x128 pixels\n",
        "    A.HorizontalFlip(p=0.5),  # Apply horizontal flip with 50% probability (for data augmentation)\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(width=128, height=128, p=1.0),  # Resize images to 128x128 pixels\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup dataset into Dataset class\n",
        "\n",
        "Convert testing, training and validation dataset into Dataset class objects."
      ],
      "metadata": {
        "id": "kifU2NdF5-Se"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcCzHQOkdeZq"
      },
      "outputs": [],
      "source": [
        "set_seed()\n",
        "\n",
        "train_ds = BrainDataset(train_df, train_transform)\n",
        "val_ds = BrainDataset(val_df, val_transform)\n",
        "test_ds = BrainDataset(test_df, test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset class statistics\n",
        "\n",
        "Output dataset class information"
      ],
      "metadata": {
        "id": "I9lSCtwo6PyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0QxymfbdeZt"
      },
      "outputs": [],
      "source": [
        "def dataset_info(dataset):\n",
        "    print(f'Size of dataset: {len(dataset)}')\n",
        "    index = random.randint(1, 40)\n",
        "    img, label = dataset[index]\n",
        "    print(f'Sample-{index} Image size: {img.shape}, Mask: {label.shape}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyDT4KFKdeZt"
      },
      "outputs": [],
      "source": [
        "print('Train dataset:')\n",
        "dataset_info(train_ds)\n",
        "print('Validation dataset:')\n",
        "dataset_info(val_ds)\n",
        "print('Test dataset:')\n",
        "dataset_info(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading\n",
        "\n"
      ],
      "metadata": {
        "id": "0whhdgc3so4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwTnQeXPdeZv"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Set seed for reproducibility in random operations.\n",
        "set_seed()\n",
        "train_dl = DataLoader(train_ds,\n",
        "                      batch_size,\n",
        "                      shuffle=True,\n",
        "                      num_workers=2,\n",
        "                      pin_memory=True)\n",
        "set_seed()\n",
        "val_dl = DataLoader(val_ds,\n",
        "                    batch_size,\n",
        "                    num_workers=2,\n",
        "                    pin_memory=True)\n",
        "test_dl = DataLoader(val_ds,\n",
        "                    batch_size,\n",
        "                    num_workers=2,\n",
        "                    pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample data batch\n",
        "\n",
        "Fetch a batch of data (images and masks) from the training DataLoader"
      ],
      "metadata": {
        "id": "cY1AAKC6NwwW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0Gy5ULodeZw"
      },
      "outputs": [],
      "source": [
        "# Fetch a batch of data (images and masks) from the training DataLoader (`train_dl`).\n",
        "images, masks = next(iter(train_dl))\n",
        "print(images.shape)\n",
        "print(masks.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## U-Net\n",
        "\n"
      ],
      "metadata": {
        "id": "CTwcBMWWPy0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions\n",
        "\n",
        "Helper Functions for Double Convolutions, Downscaling and Upscaling, Out Convolution with Sigmoid activation"
      ],
      "metadata": {
        "id": "EJQCbRGKN6ZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Leuo5yIhdeZx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Defines the DoubleConv class, consisting of two consecutive\n",
        "# convolutional layers each followed by BatchNorm and ReLU.\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "# Defines the Down class, which performs downscaling using MaxPool\n",
        "# followed by DoubleConv.\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels))\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "# Defines the Up class, which performs upscaling followed by DoubleConv.\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n",
        "                        diffY//2, diffY-diffY//2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "# Defines the OutConv class, which performs a 1x1 convolution followed by Sigmoid activation.\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net class\n",
        "\n",
        "Definition of U-Net class"
      ],
      "metadata": {
        "id": "I4uZQb3aOWRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5Y1OIt3deZy"
      },
      "outputs": [],
      "source": [
        "# Defines the UNet class, a convolutional neural network architecture\n",
        "# for semantic segmentation.\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "    # Encoder (downsampling path)\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024//factor)\n",
        "\n",
        "    # Decoder (upsampling path)\n",
        "        self.up1 = Up(1024, 512//factor, bilinear)\n",
        "        self.up2 = Up(512, 256//factor, bilinear)\n",
        "        self.up3 = Up(256, 128//factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "\n",
        "    # Output layer\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "    # Encoder path\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "\n",
        "    # Decoder path with skip connections\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "\n",
        "    # Final output\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition for U-Net\n",
        "\n",
        "Defines model to be used for current PyTorch device"
      ],
      "metadata": {
        "id": "vRn404_VOjrz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLywLEJ-deZy"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet(3, 1).to(device)\n",
        "\n",
        "# Perform a forward pass through the model with a random input tensor\n",
        "#of shape (1, 3, 128, 128), moved to the specified device (GPU or CPU).\n",
        "out = model(torch.randn(1, 3, 128, 128).to(device))\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DICE Performance Metrics\n",
        "\n",
        "Functions for DICE performance metrics"
      ],
      "metadata": {
        "id": "R7F_cBleOzRY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEjo5On3deZz"
      },
      "outputs": [],
      "source": [
        "def dice_coef_metric(pred, label):\n",
        "    intersection = 2.0 * (pred * label).sum()\n",
        "    union = pred.sum() + label.sum()\n",
        "    if pred.sum() == 0 and label.sum() == 0:\n",
        "        return 1.\n",
        "    return intersection / union\n",
        "\n",
        "# Function to calculate the Dice coefficient loss between prediction and ground truth.\n",
        "def dice_coef_loss(pred, label):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * (pred * label).sum() + smooth\n",
        "    union = pred.sum() + label.sum() + smooth\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "# Function to calculate the combined BCE (Binary Cross Entropy) and Dice loss.\n",
        "def bce_dice_loss(pred, label):\n",
        "    dice_loss = dice_coef_loss(pred, label)\n",
        "    bce_loss = nn.BCELoss()(pred, label)\n",
        "    return dice_loss + bce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loop Functions\n",
        "\n",
        "Functions implementing training and evaluation loops."
      ],
      "metadata": {
        "id": "olkSP0a_PMPr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U_BMO8gdeZ0"
      },
      "outputs": [],
      "source": [
        "# Function to perform the training loop for the model.\n",
        "def train_loop(model, loader, loss_func):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_dices = []\n",
        "\n",
        "    for i, (image, mask) in enumerate(loader):\n",
        "        image = image.to(device)\n",
        "        mask = mask.to(device)\n",
        "        outputs = model(image)\n",
        "\n",
        "# Convert outputs to numpy array for post-processing\n",
        "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "\n",
        "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "        loss = loss_func(outputs, mask)\n",
        "        train_losses.append(loss.item())\n",
        "        train_dices.append(dice)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return train_dices, train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0x6zp_RdeZ1"
      },
      "outputs": [],
      "source": [
        "# Function to perform evaluation loop for the model.\n",
        "def eval_loop(model, loader, loss_func, training=True):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for step, (image, mask) in enumerate(loader):\n",
        "            image = image.to(device)\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            outputs = model(image)\n",
        "            loss = loss_func(outputs, mask)\n",
        "\n",
        "    # Convert outputs to numpy array for post-processing\n",
        "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "\n",
        "            val_loss += loss\n",
        "            val_dice += dice\n",
        "\n",
        "        val_mean_dice = val_dice / step\n",
        "        val_mean_loss = val_loss / step\n",
        "\n",
        "        if training:\n",
        "            scheduler.step(val_mean_dice)\n",
        "\n",
        "    return val_mean_dice, val_mean_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training Function\n",
        "\n",
        "Function to defing model training algorithm."
      ],
      "metadata": {
        "id": "1JtPIGG3PX4M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt3ZGnbudeZ1"
      },
      "outputs": [],
      "source": [
        "# Function to train the model and evaluate on validation data across epochs.\n",
        "def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n",
        "    train_loss_history = []\n",
        "    train_dice_history = []\n",
        "    val_loss_history = []\n",
        "    val_dice_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_dices, train_losses = train_loop(model, train_loader, loss_func)\n",
        "        train_mean_dice = np.array(train_dices).mean()\n",
        "        train_mean_loss = np.array(train_losses).mean()\n",
        "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func)\n",
        "\n",
        "        train_loss_history.append(np.array(train_losses).mean())\n",
        "        train_dice_history.append(np.array(train_dices).mean())\n",
        "        val_loss_history.append(val_mean_loss)\n",
        "        val_dice_history.append(val_mean_dice)\n",
        "\n",
        "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs, train_mean_loss, val_mean_loss, train_mean_dice,val_mean_dice))\n",
        "\n",
        "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Training Setup\n",
        "\n",
        "Setup for training U-Net."
      ],
      "metadata": {
        "id": "xpWTQG8OPg1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9KNIGE2deZ2"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer with Adam optimizer and initial learning rate of 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Define the learning rate scheduler with ReduceLROnPlateau, monitoring 'max' validation metric, and patience of 3 epochs\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "\n",
        "# Number of epochs for training\n",
        "num_epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "Performing U-Net Training"
      ],
      "metadata": {
        "id": "AxNmviuaPnat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VZfzIcddeZ2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(train_dl, val_dl, bce_dice_loss, optimizer, scheduler, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net model evaluation\n",
        "\n",
        "U-Net model evaluation using DICE metrics"
      ],
      "metadata": {
        "id": "E2bRHmhJP89J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knQbI5JydeZ3"
      },
      "outputs": [],
      "source": [
        "def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n",
        "\n",
        "    x = np.arange(num_epochs)\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, train_dice_history, label='Train DICE', lw=3, c=\"r\")\n",
        "    plt.plot(x, val_dice_history, label='Validation DICE', lw=3, c=\"c\")\n",
        "\n",
        "    plt.title(f\"{model_name}\", fontsize=20)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epoch\", fontsize=15)\n",
        "    plt.ylabel(\"DICE\", fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage to plot Dice coefficient history for a UNet model\n",
        "plot_dice_history('U-NET Coefficient History', train_dice_history, val_dice_history, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzkUGum2deZ4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "test_dice, test_loss = eval_loop(model, test_dl, bce_dice_loss, training=False)\n",
        "print(\"Mean IoU/DICE: {:.3f}%, Loss: {:.3f}\".format((100*test_dice), test_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Data and Sample Predictions\n",
        "\n",
        "Plotting sample data and predictions based on the trained U-Net model"
      ],
      "metadata": {
        "id": "2KaDsroeQGPL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BfCNERXdeZ4"
      },
      "outputs": [],
      "source": [
        "# a sample from the test set with diagnosis label 1 and resize image and mask\n",
        "test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(24).values[0]\n",
        "image = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\n",
        "mask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))\n",
        "\n",
        "\n",
        "pred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\n",
        "pred = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\n",
        "pred = model(pred.to(device))\n",
        "pred = pred.detach().cpu().numpy()[0,0,:,:]\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "ax[0].imshow(image)\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(mask)\n",
        "ax[1].set_title(\"Mask\")\n",
        "ax[2].imshow(pred)\n",
        "ax[2].set_title(\"Prediction\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G704f5iDdeZ5"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'brain-mri-unet.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms as tt\n",
        "\n",
        "# Ensure the device is defined\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define and load the saved model\n",
        "# Replace `YourModelClass` with the actual class name of your model\n",
        "model = UNet()  # Replace with your model's class definition\n",
        "model.load_state_dict(torch.load('brain-mri-trans_unet.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Adjust the sample size to avoid sampling more than the available rows\n",
        "sample_size = 24\n",
        "available_samples = test_df[test_df[\"diagnosis\"] == 1]\n",
        "if available_samples.empty:\n",
        "    raise ValueError(\"No samples found with diagnosis == 1\")\n",
        "\n",
        "sample_size = min(sample_size, len(available_samples))\n",
        "test_sample = available_samples.sample(sample_size).values[0]\n",
        "\n",
        "# Load and resize the image and mask\n",
        "image_path = test_sample[0]  # Assuming the first column contains image paths\n",
        "mask_path = test_sample[1]   # Assuming the second column contains mask paths\n",
        "\n",
        "image = cv2.resize(cv2.imread(image_path), (128, 128))\n",
        "mask = cv2.resize(cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE), (128, 128))\n",
        "\n",
        "# Normalize and prepare the image for the model\n",
        "input_tensor = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0, 3, 1, 2)\n",
        "normalize = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "input_tensor = normalize(input_tensor).to(device)\n",
        "\n",
        "# Perform prediction\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    prediction = model(input_tensor)\n",
        "predicted_mask = prediction.detach().cpu().numpy()[0, 0, :, :]  # Convert prediction to NumPy for visualization\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct visualization\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(mask, cmap=\"gray\")\n",
        "ax[1].set_title(\"Ground Truth Mask\")\n",
        "ax[2].imshow(predicted_mask, cmap=\"viridis\")\n",
        "ax[2].set_title(\"Predicted Mask\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kcFXyftYNomc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trans-U-Net\n",
        "\n",
        "U-net with Transformer encoder"
      ],
      "metadata": {
        "id": "rLRC7hhhQeKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trans-U-net Class\n",
        "\n",
        "Definition of Trans-U-Net class"
      ],
      "metadata": {
        "id": "70L8X9drR5Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(TransUNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        # Encoder (downsampling path)\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "\n",
        "        # Transformer block\n",
        "        embed_dim = 1024 // factor\n",
        "        self.transformer = TransformerBlock(embed_dim=embed_dim, num_heads=8, depth=4)\n",
        "\n",
        "        # Decoder (upsampling path)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "\n",
        "        # Output layer\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "\n",
        "        # Transformer block\n",
        "        b, c, h, w = x5.shape  # Batch size, channels, height, width\n",
        "        x5_flattened = x5.flatten(2).permute(0, 2, 1)  # Flatten spatial dimensions and permute to [batch, sequence, channels]\n",
        "        x_transformed = self.transformer(x5_flattened)\n",
        "        x_transformed = x_transformed.permute(0, 2, 1).view(b, c, h, w)  # Restore spatial dimensions\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        x = self.up1(x_transformed, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "\n",
        "        # Final output\n",
        "        logits = self.outc(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "W1UBcZskMRkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition for Trans-U-Net\n",
        "\n",
        "Defines the Trans-U-Net model to be used for current PyTorch device"
      ],
      "metadata": {
        "id": "brxI2PDpSGaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate the TransUNet model with 3 input channels and 1 output class\n",
        "model = TransUNet(n_channels=3, n_classes=1).to(device)\n",
        "\n",
        "# Perform a forward pass through the model with a random input tensor\n",
        "# of shape (1, 3, 128, 128), moved to the specified device (GPU or CPU)\n",
        "input_tensor = torch.randn(1, 3, 128, 128).to(device)\n",
        "out = model(input_tensor)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "id": "FBZTeZeSMnI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DICE Performance Metrics\n",
        "\n",
        "Functions for DICE performance metrics"
      ],
      "metadata": {
        "id": "svLMLss3SXSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_metric(pred, label):\n",
        "    intersection = 2.0 * (pred * label).sum()\n",
        "    union = pred.sum() + label.sum()\n",
        "    if pred.sum() == 0 and label.sum() == 0:\n",
        "        return 1.\n",
        "    return intersection / union\n",
        "\n",
        "# Function to calculate the Dice coefficient loss between prediction and ground truth.\n",
        "def dice_coef_loss(pred, label):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * (pred * label).sum() + smooth\n",
        "    union = pred.sum() + label.sum() + smooth\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "# Function to calculate the combined BCE (Binary Cross Entropy) and Dice loss.\n",
        "def bce_dice_loss(pred, label):\n",
        "    dice_loss = dice_coef_loss(pred, label)\n",
        "    bce_loss = nn.BCELoss()(pred, label)\n",
        "    return dice_loss + bce_loss"
      ],
      "metadata": {
        "id": "DtpmtdvbMp4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loop Functions\n",
        "\n",
        "Functions implementing training and evaluation loops."
      ],
      "metadata": {
        "id": "SBzth3a2ScDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform the training loop for the model.\n",
        "def train_loop(model, loader, loss_func):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_dices = []\n",
        "\n",
        "    for i, (image, mask) in enumerate(loader):\n",
        "        image = image.to(device)\n",
        "        mask = mask.to(device)\n",
        "        outputs = model(image)\n",
        "\n",
        "# Convert outputs to numpy array for post-processing\n",
        "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "\n",
        "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "        loss = loss_func(outputs, mask)\n",
        "        train_losses.append(loss.item())\n",
        "        train_dices.append(dice)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return train_dices, train_losses"
      ],
      "metadata": {
        "id": "_kcIXf_DMsCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform evaluation loop for the model.\n",
        "def eval_loop(model, loader, loss_func, training=True):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for step, (image, mask) in enumerate(loader):\n",
        "            image = image.to(device)\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            outputs = model(image)\n",
        "            loss = loss_func(outputs, mask)\n",
        "\n",
        "    # Convert outputs to numpy array for post-processing\n",
        "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "\n",
        "            val_loss += loss\n",
        "            val_dice += dice\n",
        "\n",
        "        val_mean_dice = val_dice / step\n",
        "        val_mean_loss = val_loss / step\n",
        "\n",
        "        if training:\n",
        "            scheduler.step(val_mean_dice)\n",
        "\n",
        "    return val_mean_dice, val_mean_loss"
      ],
      "metadata": {
        "id": "BtB_dYZOMuVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training Function\n",
        "\n",
        "Function to defing model training algorithm."
      ],
      "metadata": {
        "id": "y4v73DW4S1Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model and evaluate on validation data across epochs.\n",
        "def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n",
        "    train_loss_history = []\n",
        "    train_dice_history = []\n",
        "    val_loss_history = []\n",
        "    val_dice_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_dices, train_losses = train_loop(model, train_loader, loss_func)\n",
        "        train_mean_dice = np.array(train_dices).mean()\n",
        "        train_mean_loss = np.array(train_losses).mean()\n",
        "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func)\n",
        "\n",
        "        train_loss_history.append(np.array(train_losses).mean())\n",
        "        train_dice_history.append(np.array(train_dices).mean())\n",
        "        val_loss_history.append(val_mean_loss)\n",
        "        val_dice_history.append(val_mean_dice)\n",
        "\n",
        "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs, train_mean_loss, val_mean_loss, train_mean_dice,val_mean_dice))\n",
        "\n",
        "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history"
      ],
      "metadata": {
        "id": "WtwVOzH_Mwkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Training Setup\n",
        "\n",
        "Setup for training U-Net."
      ],
      "metadata": {
        "id": "CVpLLknsS54N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer with Adam optimizer and initial learning rate of 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Define the learning rate scheduler with ReduceLROnPlateau, monitoring 'max' validation metric, and patience of 3 epochs\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "\n",
        "# Number of epochs for training\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "PBF4KyfDMy0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "Performing U-Net Training"
      ],
      "metadata": {
        "id": "m-K9Lf4oS9td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(train_dl, val_dl, bce_dice_loss, optimizer, scheduler, num_epochs)"
      ],
      "metadata": {
        "id": "KUh5c8MYM08X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net model evaluation\n",
        "\n",
        "U-Net model evaluation using DICE metrics"
      ],
      "metadata": {
        "id": "eSy0V1lzTAxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n",
        "\n",
        "    x = np.arange(num_epochs)\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, train_dice_history, label='Train DICE', lw=3, c=\"r\")\n",
        "    # plt.plot(x, val_dice_history, label='Validation DICE', lw=3, c=\"c\")\n",
        "\n",
        "    plt.title(\"Trans-Unet Coefficient History\", fontsize=20)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epoch\", fontsize=15)\n",
        "    plt.ylabel(\"DICE\", fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage to plot Dice coefficient history for a UNet model\n",
        "plot_dice_history('U-NET Coefficient History', train_dice_history, val_dice_history, num_epochs)"
      ],
      "metadata": {
        "id": "9EnfJfHJM5Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test_dice, test_loss = eval_loop(model, test_dl, bce_dice_loss, training=False)\n",
        "print(\"Mean IoU/DICE: {:.3f}%, Loss: {:.3f}\".format((100*test_dice), test_loss))"
      ],
      "metadata": {
        "id": "O_nmQPWBM-l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Data and Sample Predictions\n",
        "\n",
        "Plotting sample data and predictions based on the trained U-Net model"
      ],
      "metadata": {
        "id": "IhnkY3m4TG0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms as tt\n",
        "\n",
        "# Adjust the sample size to avoid sampling more than the available rows\n",
        "sample_size = 24\n",
        "available_samples = test_df[test_df[\"diagnosis\"] == 1]\n",
        "if available_samples.empty:\n",
        "    raise ValueError(\"No samples found with diagnosis == 1\")\n",
        "\n",
        "sample_size = min(sample_size, len(available_samples))\n",
        "test_sample = available_samples.sample(sample_size).values[0]\n",
        "\n",
        "# Load and resize the image and mask\n",
        "image_path = test_sample[0]  # Assuming the first column contains image paths\n",
        "mask_path = test_sample[1]   # Assuming the second column contains mask paths\n",
        "\n",
        "image = cv2.resize(cv2.imread(image_path), (128, 128))\n",
        "mask = cv2.resize(cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE), (128, 128))\n",
        "\n",
        "# Normalize and prepare the image for the model\n",
        "pred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0, 3, 1, 2)\n",
        "pred = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\n",
        "\n",
        "# Ensure the model and device are defined\n",
        "if 'model' not in globals() or 'device' not in globals():\n",
        "    raise ValueError(\"Model and device must be defined before running the code\")\n",
        "\n",
        "pred = model(pred.to(device))\n",
        "pred = pred.detach().cpu().numpy()[0, 0, :, :]\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for proper visualization\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(mask, cmap=\"gray\")\n",
        "ax[1].set_title(\"Mask\")\n",
        "ax[2].imshow(pred, cmap=\"viridis\")\n",
        "ax[2].set_title(\"Prediction\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2ZyWkxVeNCbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'brain-mri-trans_unet.pth')"
      ],
      "metadata": {
        "id": "eP8QwauZNDRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms as tt\n",
        "\n",
        "# Ensure the device is defined\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define and load the saved model\n",
        "# Replace `YourModelClass` with the actual class name of your model\n",
        "model = TransUNet(n_channels=3, n_classes=1)  # Replace with your model's class definition\n",
        "model.load_state_dict(torch.load('brain-mri-trans_unet.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Adjust the sample size to avoid sampling more than the available rows\n",
        "sample_size = 24\n",
        "available_samples = test_df[test_df[\"diagnosis\"] == 1]\n",
        "if available_samples.empty:\n",
        "    raise ValueError(\"No samples found with diagnosis == 1\")\n",
        "\n",
        "sample_size = min(sample_size, len(available_samples))\n",
        "test_sample = available_samples.sample(sample_size).values[0]\n",
        "\n",
        "# Load and resize the image and mask\n",
        "image_path = test_sample[0]  # Assuming the first column contains image paths\n",
        "mask_path = test_sample[1]   # Assuming the second column contains mask paths\n",
        "\n",
        "image = cv2.resize(cv2.imread(image_path), (128, 128))\n",
        "mask = cv2.resize(cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE), (128, 128))\n",
        "\n",
        "# Normalize and prepare the image for the model\n",
        "input_tensor = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0, 3, 1, 2)\n",
        "normalize = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "input_tensor = normalize(input_tensor).to(device)\n",
        "\n",
        "# Perform prediction\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    prediction = model(input_tensor)\n",
        "predicted_mask = prediction.detach().cpu().numpy()[0, 0, :, :]  # Convert prediction to NumPy for visualization\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct visualization\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(mask, cmap=\"gray\")\n",
        "ax[1].set_title(\"Ground Truth Mask\")\n",
        "ax[2].imshow(predicted_mask, cmap=\"viridis\")\n",
        "ax[2].set_title(\"Predicted Mask\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IgtyrGcDNFVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}